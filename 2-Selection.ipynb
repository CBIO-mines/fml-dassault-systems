{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Notebook 2 : Sélection et évaluation de modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Notebook préparé par [Chloé-Agathe Azencott](http://cazencott.info) avec l'aide d'[Arthur Imbert](https://github.com/Henley13).\n",
    "\n",
    "Dans ce notebook il s'agit\n",
    "* d'évaluer un modèle sur un jeu de test\n",
    "* de choisir la valeur d'un hyperparamètre d'un algorithme d'apprentissage\n",
    "* de comprendre l'intérêt de la régression polynomiale et de la régularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# charger numpy as np, matplotlib as plt\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', **{'size': 12}) # règle la taille de police globalement pour les plots (en pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Nous allons travailler avec un jeu de données contenant des informations physico-chimiques sur un certain nombre de vins portugais (vinho verde), ainsi que les notes qui leur ont été attribuées par des gens qui les ont goûtés. Notre but est d'automatiser ce processus : nous voulons prédire directement la note des vins à partir de leurs caractéristiques physico-chimiques, afin d'assister les œnologues, améliorer la production de vin, et cibler les goûts de consomateurs de niche.\n",
    "\n",
    "Ce jeu de données est disponible sur l'archive UCI de jeux de données de machine learning, sur laquelle vous trouverez de nombreux jeux de données classiques : http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/. Pas besoin de le télécharger, il est déjà dans votre répertoire, dans le fichier `data/winequality-white.csv`. Nous allons le charger avec pandas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/winequality-white.csv', # nom du fichier\n",
    "                   sep=\";\" # séparateur de colonnes\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "__Alternativement :__ Si vous avez besoin de télécharger le fichier (par exemple sur colab) :"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9",
   "metadata": {},
   "source": [
    "!wget https://raw.githubusercontent.com/CBIO-mines/fml-dassault-systems/main/data/winequality-white.csv\n",
    "\n",
    "df = pd.read_csv('winequality-white.csv', # nom du fichier\n",
    "                   sep=\";\" # séparateur de colonnes\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant examiner ce fichier directement dans notre notebook, par exemple en en regardant les premières lignes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Création des matrices X et y de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop(columns=['quality']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "__Question :__ Combien d'exemples d'apprentissage contiennent les données ? Combien de variables ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "__Question :__ Que pensez-vous de l'utilisation d'une régression linéaire pour résoudre ce problème ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transformation en un problème de classification binaire\n",
    "\n",
    "Nous allons essayer de classifier les vins entre vins de bonne qualité (score >= 6) et les autres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where(y >= 6, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 2. Séparation des données en un jeu d'entraînement et un jeu de test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Pour pouvoir évaluer un modèle d'apprentissage de façon non-biaisée, nous avons besoin de créer un jeu de test contenant des données sur lequel le modèle n'a pas été entraîné. Ce jeu de test correspond à des données « nouvelles ».\n",
    "\n",
    "Pour ce faire, nous allons utiliser la fonction [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) du module `model_selection` de scikit-learn :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    model_selection.train_test_split(X, y,\n",
    "                                    test_size=0.3, # 30% des données dans le jeu de test\n",
    "                                    random_state=42 # graine du générateur aléatoire\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Fixer la graine du générateur aléatoire nous permet d'obtenir les mêmes jeux d'entraînement et de test en relançant la commande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "__Question :__ Combien d'échantillons le jeu d'entraînement (X_train, y_train) contient-il ? Et le jeu de test (X_test, y_test) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transformation des variables\n",
    "Nous avons vu dans le Notebook 1 qu'il est plus raisonnable de centrer-réduire les variables avant de procéder.\n",
    "\n",
    "N'oublions pas que le jeu de test est prétendu non-connu au moment de l'entraînement : il faut utiliser __uniquement le jeu d'entraînement__ pour centrer-réduire les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un \"standardiseur\" et le calibrer sur les données d'entraînement\n",
    "std_scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "# Appliquer la standardisation aux données d'entraînement\n",
    "X_train_scaled = std_scaler.transform(X_train)\n",
    "\n",
    "# Appliquer la standardisation aux données de test\n",
    "X_test_scaled = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Plus proches voisins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Nous allons maintenant évaluer la capacité d'un algorithme des plus proches voisins à classifier les vins.\n",
    "\n",
    "Pour cela, nous faisons appel à la classe [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) du module `neighbors` de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Entrainement sur le jeu d'entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Comme dans le Notebook 1, on commence par instancier un objet de la classe qui nous intéresse :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = neighbors.KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "On peut ensuite l'entraîner sur les données d'entrainement centrées-réduites :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### Prédictions sur le jeu de test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "On peut maintenant utiliser le classifieur entraîné sur les données de test, toujours centrées-réduites :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = model_knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### Évaluation de la performance\n",
    "\n",
    "De nombreuses métriques permettent d'évaluer la performance d'un algorithme de classification (voir [la doc de scikit-learn à ce sujet](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)). La __matrice de confusion__ en particulier permet de visualiser combien d'exemple de chaque classe reçoivent chacune des étiquettes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "__Question :__ Combien il y-a-t'il de vrais positifs ? De faux négatifs ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "La matrice de confusion peut être résumée par le [score F1 ](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"F1 du kNN sur le jeu de test : %.2f\" % metrics.f1_score(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Sélection du nombre de plus proches voisins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "__Question :__ Combien de plus proches voisins a-t-on utilisé dans la section précédente ? Appuyez-vous sur la documentation, par exemple en tapant\n",
    "```\n",
    " neighbors.KNeighborsClassifier?\n",
    " ```\n",
    "dans une cellule ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors.KNeighborsClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mise en place d'une validation croisée\n",
    "\n",
    "Le nombre de plus proches voisins (`n_neighbors`) est un __hyperparamètre__ de l'algorithme des plus proches voisins : il ne fait pas partie des paramètres du modèle appris par l'algorithme, mais nous devons le fixer nous-mêmes avant l'entraînement.\n",
    "\n",
    "Nous allons maintenant _choisir_ ce nombre de plus proches voisins par une procédure de __recherche en grille__ (_gridsearch_), qui consiste à _comparer_ les performances de modèles entraînés en utilisant des valeurs prédéfinies (la grille) de l'hyperparamètre. \n",
    "\n",
    "Attention ! Si nous voulons pouvoir utiliser le jeu de test pour évaluer l'erreur de généralisation du modèle utilisant la valeur optimale du nombre de plus proches voisins, nous ne pouvons pas l'utiliser aussi pour cette étape de sélection, car sinon nous pourrions biaiser le modèle et surapprendre.\n",
    "\n",
    "Pour comparer nos modèles __sur le jeu d'entraînement__, nous allons utiliser une __validation croisée__, encore une fois grâce au module [http://scikit-learn.org/stable/model_selection.html#model-selection](model-selection) de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 10\n",
    "\n",
    "# Créer un objet KFold qui permettra de cross-valider en n_folds folds\n",
    "kf = model_selection.KFold(n_splits=n_folds,  \n",
    "                           shuffle=True # mélanger les échantillons avant de créer les folds\n",
    "                          )\n",
    "\n",
    "# Utiliser kf pour partager le jeu d'entraînement en n_folds folds. \n",
    "# kf.split retourne un iterateur (consommé après une boucle).\n",
    "# Pour pouvoir se servir plusieurs fois des mêmes folds, nous transformons cet itérateur en liste d'indices :\n",
    "kf_indices = list(kf.split(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "`kf_indices` contient 10 paires de deux vecteurs d'indices. \n",
    "\n",
    "Chacune de ces paires correspond à un fold. \n",
    "\n",
    "Le premier vecteur donne les indices des échantillons formant la partie entraînement de ce fold. Le deuxième donne les indices des échantillons formant la partie test de ce fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (idx, fold) in enumerate(kf_indices):\n",
    "    print(\"Le fold %d contient %d observations pour l'entraînement and %d observations pour le test\" % (idx, len(fold[0]), len(fold[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "__Question :__ Combien de fois chaque échantillon apparaît-il dans la partie entraînement d'un fold ? Dans la partie test ? (Il n'est pas nécessaire d'écrire de code pour répondre.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Recherche en grille\n",
    "\n",
    "Nous allons commencer par définir une __grille__ de valeurs d'hyperparamètres, c'est à dire une liste de valeurs du nombre de plus proches voisins à évaluer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = np.arange(3, 50, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "__Question :__ Pourquoi sélectionner uniquement des nombres impairs de voisins ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "Nous allons maintenant utiliser la classe [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) du module `model_selection` de scikit-learn pour déterminer la valeur optimale du nombre de plus proches voisins par recherche en grille :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation d'un objet GridSearchCV\n",
    "grid = model_selection.GridSearchCV(neighbors.KNeighborsClassifier(), # prédicteur à évaluer\n",
    "                                    {'n_neighbors':k_values}, # dictionnaire de valeurs d'hyperparamètres\n",
    "                                    cv=kf_indices, # validation croisée à utiliser\n",
    "                                    scoring='f1' # métrique d'évaluation de la performance\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "Nous allons aussi utiliser la [commande magique time](https://ipython.readthedocs.io/en/stable/interactive/magics.html) pour mesurer le temps de calcul d'une cellule de notre notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Utilisation de cet objet sur les données d'entraînement (centrées-réduites)\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "La valeur optimale de l'hyperparamètre est donnée par :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "Le code suivant permet d'afficher la performance du modèle selon la valeur de l'hyperparamètre :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test_score = grid.cv_results_['mean_test_score']\n",
    "stde_test_score = grid.cv_results_['std_test_score'] / np.sqrt(n_folds) # standard error\n",
    "\n",
    "p = plt.plot(k_values, mean_test_score)\n",
    "plt.plot(k_values, (mean_test_score + stde_test_score), '--', color=p[0].get_color())\n",
    "plt.plot(k_values, (mean_test_score - stde_test_score), '--', color=p[0].get_color())\n",
    "plt.fill_between(k_values, (mean_test_score + stde_test_score), \n",
    "                 (mean_test_score - stde_test_score), alpha=0.2)\n",
    "\n",
    "best_index = np.where(k_values == grid.best_params_['n_neighbors'])[0][0]\n",
    "plt.scatter(k_values[best_index], mean_test_score[best_index])\n",
    "\n",
    "\n",
    "plt.xlabel('nombre de plus proches voisins')\n",
    "plt.ylabel('F1')\n",
    "plt.title(\"Performance (en validation croisée) le long de la grille\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "### Modèle optimal de plus proches voisins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meilleur F1 en validation croisée : %.3f\" % grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "Le modèle entraîné sur l'intégralité des données fournies à `grid.fit` avec la (les) meilleure(s) valeur(s) d'hyperparamètre(s) est donné par `grid.best_estimator_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_knn_opt = grid.best_estimator_.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred_knn_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"F1 du kNN (k optimal) sur le jeu de test : %.2f\" % metrics.f1_score(y_test, y_pred_knn_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "## 5. Régression logistique régularisée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "### Performance d'une régression logistique non-régularisée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "Nous allons maintenant entraîner une régression __logistique__ (car nous avons un problème de classification) _sur le jeu d'entraînement_ et l'évaluer _sur le jeu de test_.\n",
    "\n",
    "Nous utilisons la classe [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) du module `linear_model` de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle de régression linéaire \n",
    "model_rlog = linear_model.LogisticRegression(penalty=None # modèle non régularisé pour l'instant\n",
    "                                            )\n",
    "\n",
    "# Entraîner ce modèle sur (X_train_scaled, y_train)\n",
    "model_rlog.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "Alternativement (anciennes versions de scikit-learn) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle de régression linéaire \n",
    "model_rlog = linear_model.LogisticRegression(penalty='l2', C=1e6 # modèle non régularisé pour l'instant\n",
    "                                            )\n",
    "\n",
    "# Entraîner ce modèle sur (X_train_scaled, y_train)\n",
    "model_rlog.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédire les étiquettes du jeu de test\n",
    "y_pred_rlog = model_rlog.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred_rlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"F1 d'une régression logistique sur le jeu de test : %.2f\" % metrics.f1_score(y_test, y_pred_rlog))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "__Question :__ Que pensez-vous de la qualité du modèle ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "### Coefficients du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le nombre de variables\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "# Afficher pour chaque variable son coefficient dans le modèle\n",
    "plt.scatter(range(num_features), # en abcisse : indices des variables\n",
    "            model_rlog.coef_ # en ordonnées : leur poids dans le modèle\n",
    "           )\n",
    "\n",
    "# Étiqueter les graduations de l'axe des abcsisses\n",
    "tmp = plt.xticks(range(num_features), # une marque par variable\n",
    "                 list(df.columns[:-1]),  # afficher le nom de la variable\n",
    "                 rotation=90, # tourner les étiquettes de 90 degrés\n",
    "                 fontsize=14)\n",
    "\n",
    "# Étiqueter les axes\n",
    "tmp = plt.xlabel('Variable', fontsize=14)\n",
    "tmp = plt.ylabel('Coefficient', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "### Régularisation ridge\n",
    "\n",
    "Nous allons maintenant ajouter une régularisation l2 (ou ridge) à cette régression logistique.\n",
    "\n",
    "Ici il y a peu de variables et leurs coefficients prennent des valeurs faibles : il n'est pas certain que la régularisation soit nécessaire, mais comme ce jeu de données comporte peu de variables, nous pouvons l'utiliser pour regarder l'effet de la régularisation sur les valeurs des coefficients du modèle appris.\n",
    "\n",
    "Commençons par nous donner une grille de valeurs pour le paramètre de régularisation `C`. \n",
    "\n",
    "Attention ! Plus `C` est grand, _moins_ il y a de régularisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values = np.logspace(-3, 3, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "Nous allons maintenant utiliser non pas `GridSearchCV` mais implémenter notre recherche en grille nous-mêmes, afin d'avoir accès aux valeurs des coefficients de chacun des modèles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "f1_per_c = [] # pour enregistrer les valeurs du score F1 pour chacune des 50 valeurs de C\n",
    "weights_per_c = [] # pour enregistrer les coefficients associés à chaque variable,  \n",
    "                   # pour les 50 valeurs de C\n",
    "for c_val in c_values:\n",
    "    # Créer un modèle de régression logistique régularisée par le paramètre c_val\n",
    "    model_ridge = linear_model.LogisticRegression(penalty='l2', C=c_val)\n",
    "    \n",
    "    # Calculer la performance en validation croisée du modèle\n",
    "    f1 = model_selection.cross_val_score(model_ridge, # prédicteur à évaluer\n",
    "                                         X_train_scaled, y_train, # données d'entrainement\n",
    "                                         cv=kf_indices, # validation croisée à utiliser\n",
    "                                         scoring='f1' # métrique d'évaluation de la performance\n",
    "                                         )\n",
    "    f1_per_c.append(f1)\n",
    "    \n",
    "    # Entrainer le modèle sur le jeu d'entrainement total \n",
    "    model_ridge.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Enregistrer les coefficients de régression \n",
    "    weights_per_c.append(model_ridge.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "### Évolution de la performance en fonction du coefficient de régularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test_score = np.mean(np.array(f1_per_c), axis=1)\n",
    "stde_test_score = np.std(np.array(f1_per_c), axis=1) / np.sqrt(n_folds) # standard error\n",
    "\n",
    "p = plt.plot(c_values, mean_test_score)\n",
    "plt.plot(c_values, (mean_test_score + stde_test_score), '--', \n",
    "         color=p[0].get_color()) # réutiliser la même couleur que précédemment au lieu d'avancer\n",
    "plt.plot(c_values, (mean_test_score - stde_test_score), '--', color=p[0].get_color())\n",
    "plt.fill_between(c_values, (mean_test_score + stde_test_score), \n",
    "                 (mean_test_score - stde_test_score), alpha=0.2)\n",
    "\n",
    "\n",
    "plt.xscale('log') # utiliser une échelle logarithmique en abcisse\n",
    "\n",
    "# Étiqueter les axes\n",
    "tmp = plt.xlabel('Valeur de C', fontsize=14)\n",
    "tmp = plt.ylabel('F1 moyen', fontsize=14)\n",
    "\n",
    "# Titre\n",
    "tmp = plt.title(\"Performance (validation croisée) de la régression logistique\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "__Question :__ Comment l'erreur du modèle (en validation croisée) évolue-t-elle en fonction de la quantité de régularisation ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "### Modèle optimal de régression ridge\n",
    "\n",
    "Nous pouvons maintenant sélectionner, parmi nos 50 modèles de régression ridge, celui qui a la plus petite erreur en validation croisée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver l'index de la valeur optimale de C\n",
    "best_C_idx = np.argmax(np.mean(f1_per_c, axis=1))\n",
    "\n",
    "# Valeur de C optimale\n",
    "c_opt = c_values[best_C_idx]\n",
    "print(\"Valeur de C optimale (regression ridge) : %.3e\" % c_opt)\n",
    "\n",
    "# MSE correspondante\n",
    "print(\"Score F1 (validation croisée) du modèle de regression logistique régularisée optimal : %.2f +/- %.2f\" % \\\n",
    "     (np.mean(np.array(f1_per_c)[best_C_idx]), # valeur moyenne\n",
    "      np.std(np.array(f1_per_c)[best_C_idx]) # écart-type\n",
    "     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "### Évolution des coefficients de régression en fonction de la régularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une figure\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "\n",
    "lines = plt.plot(c_values, \n",
    "                 weights_per_c # ordonnée = valeurs des coefficients de régression\n",
    "                ) \n",
    "plt.xscale('log') # échelle logarithmique en abcisse\n",
    "\n",
    "# Afficher de nouveau (à l'abscisse 2x1e3) les coefficients de régression obtenus sans régularisation \n",
    "for coeff in model_rlog.coef_[0]:\n",
    "    plt.scatter([2e3], [coeff])\n",
    "\n",
    "# Marquer la valeur optimale de C d'une barre verticale\n",
    "plt.plot([c_opt, c_opt], [-0.75, 1.25], 'k--')\n",
    "    \n",
    "# Afficher la légende\n",
    "tmp = plt.legend(lines, # récupérer l'identifiant \n",
    "                 list(df.columns), # nom de chaque variable\n",
    "                 frameon=False, # pas de cadre autour de la légende\n",
    "                 loc=(1, 0),  # placer la légende à droite de l'image\n",
    "                 fontsize=14)\n",
    "\n",
    "tmp = plt.xlabel('Valeur de C', fontsize=14)\n",
    "tmp = plt.ylabel('Coefficient de régression', fontsize=14)\n",
    "\n",
    "tmp = plt.title('Régression logistique', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "__Question :__ Comment les coefficients du modèle évoluent-ils en fonction de la quantité de régularisation ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97",
   "metadata": {},
   "source": [
    "__Question :__ Ces coefficients vous semblent-ils cohérents avec ceux obtenus pour la régression logistique non-régularisée ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "## 6. Régularisation ridge sur un cas d'école"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "Pour mieux comprendre la régularisation ridge, nous allons simuler un jeu de données non-linéaire qui prendra la forme d'une courbe sinusoïdale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100",
   "metadata": {},
   "source": [
    "### Simulation de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = 30\n",
    "\n",
    "np.random.seed(13)\n",
    "\n",
    "# vrai modèle \n",
    "def true_model(X):\n",
    "    return np.cos(1.5 * np.pi * X) * 5\n",
    "\n",
    "# échantillons \"ground truth\" tirés du vrai modèle \n",
    "X_ground_truth = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "y_ground_truth = true_model(X_ground_truth)\n",
    "\n",
    "# données = observations tirées du vrai modèle puis bruitées\n",
    "X = np.sort(np.random.rand(nb_samples, 1))\n",
    "y = true_model(X)\n",
    "# ajout du bruit\n",
    "y += np.random.randn(nb_samples, 1) * 0.3\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dessiner le vrai modèle\n",
    "plt.plot(X_ground_truth, y_ground_truth, label=\"Vrai modèle\", linewidth=2)\n",
    "\n",
    "# Afficher les données simulées\n",
    "plt.scatter(X, y, label=\"Données simulées\", marker=\"o\")\n",
    "\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "### Séparation entrainement / test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105",
   "metadata": {},
   "source": [
    "### Régression linéaire "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106",
   "metadata": {},
   "source": [
    "__Question :__ Combien de variables avons-nous dans notre problème ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107",
   "metadata": {},
   "source": [
    "Entrainons une régression linéaire « classique » (comme celle vue dans le Notebook 1) sur `(X_train, y_train)` et évaluons sa performance d'une part sur le jeu d'entraînement et d'autre part sur le jeu de test. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108",
   "metadata": {},
   "source": [
    "__Question :__ Pourquoi comparer ces deux performances ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110",
   "metadata": {},
   "source": [
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE \n",
    "print(\"RMSE d'une régression linéaire :\")\n",
    "# Sur le jeu d'entrainement\n",
    "rmse_reg_train = metrics.root_mean_squared_error(y_train, reg.predict(X_train))\n",
    "print(\"\\r train: {0:0.2f}\".format(rmse_reg_train))\n",
    "# Sur le jeu de test\n",
    "rmse_reg_test = metrics.root_mean_squared_error(y_test, reg.predict(X_test))\n",
    "print(\"\\r test: {0:0.2f}\".format(rmse_reg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112",
   "metadata": {},
   "source": [
    "Nous allons maintenant afficher le modèle appris sur le graphe précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dessiner le vrai modèle\n",
    "plt.plot(X_ground_truth, y_ground_truth, label=\"Vrai modèle\", linewidth=2)\n",
    "\n",
    "# Afficher le modèle appris\n",
    "y_model = reg.predict(X_ground_truth)\n",
    "plt.plot(X_ground_truth, y_model, label=\"Modèle appris\", linewidth=2)\n",
    "\n",
    "# Afficher les données simulées\n",
    "plt.scatter(X_train, y_train, label=\"Données simulées (train)\", marker=\"o\")\n",
    "plt.scatter(X_test, y_test, label=\"Données simulées (test)\", marker=\"D\")\n",
    "\n",
    "# format plot\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Régression linéaire\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114",
   "metadata": {},
   "source": [
    "__Question :__ Que pensez-vous de la performance de la régression linéaire ici ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115",
   "metadata": {},
   "source": [
    "### Régression polynomiale "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116",
   "metadata": {},
   "source": [
    "La régression polynomiale consiste à apprendre un modèle non-linéaire en apprenant un modèle linéaire sur un nouvel ensemble de variables, formé de monomes des variables décrivant nos données.\n",
    "\n",
    "De manière générale, pour un problème décrit par $p$ variables $(X_1, X_2, \\dots, X_p)$, une régression polynomiale de degré $d$ est une régression linéaire sur les variables $(X_1, X_2, \\dots, X_p, X_1^2, X_1 X_2, \\dots, X_p^2, \\dots, X_p^d)$. Remarquez que nous créons ainsi un grand nombre de variables, corrélées entre elles ; nous gagnons en finesse de modélisation, mais perdons en complexité du modèle, risque de surapprentissage, et fléau de la dimension.\n",
    "\n",
    "Une telle transformation est possible avec la classe `PolynomialFeatures` de `sklearn.preprocessing`.\n",
    "\n",
    "Ici, il s'agit donc de régresser une droite à partir des puissances de $X$ et non plus de $X$ uniquement : on approche le vrai modèle par un polynôme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul des puissances de x, jusqu'au degré 15\n",
    "polynomial_features = preprocessing.PolynomialFeatures(degree=15)#, include_bias=False)\n",
    "\n",
    "# création des jeux de données correspondants\n",
    "X_train_poly = polynomial_features.fit_transform(X_train)\n",
    "X_test_poly = polynomial_features.transform(X_test)\n",
    "X_ground_truth_poly = polynomial_features.transform(X_ground_truth)\n",
    "\n",
    "print(X_train_poly.shape)\n",
    "print(X_test_poly.shape)\n",
    "print(X_ground_truth_poly.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118",
   "metadata": {},
   "source": [
    "__Question :__ Combien de variables avons-nous maintenant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement\n",
    "reg_poly = linear_model.LinearRegression()\n",
    "reg_poly.fit(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE \n",
    "print(\"RMSE d'une régression polynomiale :\")\n",
    "# Sur le jeu d'entrainement\n",
    "rmse_reg_poly_train = metrics.root_mean_squared_error(y_train, reg_poly.predict(X_train_poly))\n",
    "print(\"\\r train: {0:0.2f}\".format(rmse_reg_poly_train))\n",
    "# Sur le jeu de test\n",
    "rmse_reg_poly_test = metrics.root_mean_squared_error(y_test, reg_poly.predict(X_test_poly))\n",
    "print(\"\\r test: {0:0.2f}\".format(rmse_reg_poly_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122",
   "metadata": {},
   "source": [
    "__Question :__ Comparez les performances du modèle sur le jeu d'entrainement et le jeu de test. Que conclure ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123",
   "metadata": {},
   "source": [
    "Nous allons maintenant afficher le modèle appris sur le graphe précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dessiner le vrai modèle\n",
    "plt.plot(X_ground_truth, y_ground_truth, label=\"Vrai modèle\", linewidth=2)\n",
    "\n",
    "# Afficher le modèle appris\n",
    "plt.plot(X_ground_truth, reg_poly.predict(X_ground_truth_poly), label=\"Modèle appris\", linewidth=2)\n",
    "\n",
    "# Afficher les données simulées\n",
    "plt.scatter(X_train, y_train, label=\"Données simulées (train)\", marker=\"o\")\n",
    "plt.scatter(X_test, y_test, label=\"Données simulées (test)\", marker=\"D\")\n",
    "\n",
    "# format plot\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Régression polynomiale\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.ylim([-6, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125",
   "metadata": {},
   "source": [
    "__Question :__ Que pouvez-vous conclure sur le choix de la régression polynomiale ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Coefficients du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le nombre de variables\n",
    "num_features = X_train_poly.shape[1]\n",
    "\n",
    "# Afficher pour chaque variable son coefficient dans le modèle\n",
    "plt.scatter(range(num_features), # en abcisse : indices des variables\n",
    "            reg_poly.coef_ # en ordonnées : leur poids dans le modèle\n",
    "           )\n",
    "\n",
    "# Étiqueter les axes\n",
    "tmp = plt.xlabel('Variable', fontsize=14)\n",
    "tmp = plt.ylabel('Coefficient', fontsize=14)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128",
   "metadata": {},
   "source": [
    "__Question :__ Que remarquez-vous ? Faites bien attention à l'échelle des coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129",
   "metadata": {},
   "source": [
    "### Régression polynomiale régularisée ridge\n",
    "\n",
    "Comme la régression polynomiale surapprend, nous allons maintenant lui appliquer un terme de régularisation ridge pour essayer de compenser cet effet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement\n",
    "ridge_poly = linear_model.Ridge(alpha=0.01, random_state=13)\n",
    "ridge_poly.fit(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE \n",
    "print(\"RMSE d'une régression polynomiale régularisée :\")\n",
    "# Sur le jeu d'entrainement\n",
    "rmse_ridge_poly_train = metrics.root_mean_squared_error(y_train, ridge_poly.predict(X_train_poly))\n",
    "print(\"\\r train: {0:0.2f}\".format(rmse_ridge_poly_train))\n",
    "# Sur le jeu de test\n",
    "rmse_ridge_poly_test = metrics.root_mean_squared_error(y_test, ridge_poly.predict(X_test_poly))\n",
    "print(\"\\r test: {0:0.2f}\".format(rmse_ridge_poly_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133",
   "metadata": {},
   "source": [
    "__Question :__ Comparez les performances du modèle sur le jeu d'entrainement et le jeu de test. Que conclure ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134",
   "metadata": {},
   "source": [
    "Nous allons maintenant afficher le modèle appris sur le graphe précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dessiner le vrai modèle\n",
    "plt.plot(X_ground_truth, y_ground_truth, label=\"Vrai modèle\", linewidth=2)\n",
    "\n",
    "# Afficher le modèle appris\n",
    "plt.plot(X_ground_truth, ridge_poly.predict(X_ground_truth_poly), label=\"Modèle appris\", linewidth=2)\n",
    "\n",
    "# Afficher les données simulées\n",
    "plt.scatter(X_train, y_train, label=\"Données simulées (train)\", marker=\"o\")\n",
    "plt.scatter(X_test, y_test, label=\"Données simulées (test)\", marker=\"D\")\n",
    "\n",
    "# format plot\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Régression polynomiale régularisée\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136",
   "metadata": {},
   "source": [
    "__Question :__ Que pouvez-vous conclure sur le choix de la régularisation Ridge ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Coefficients du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le nombre de variables\n",
    "num_features = X_train_poly.shape[1]\n",
    "\n",
    "# Afficher pour chaque variable son coefficient dans le modèle\n",
    "plt.scatter(range(num_features), # en abcisse : indices des variables\n",
    "            ridge_poly.coef_ # en ordonnées : leur poids dans le modèle\n",
    "           )\n",
    "\n",
    "# Étiqueter les axes\n",
    "tmp = plt.xlabel('Variable', fontsize=14)\n",
    "tmp = plt.ylabel('Coefficient', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139",
   "metadata": {},
   "source": [
    "__Question :__ Que remarquez-vous maintenant ? Quel est l'effet de la régularisation sur les coefficients du modèle ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140",
   "metadata": {},
   "source": [
    "### Régression polynomiale régularisée lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement\n",
    "lasso_poly = linear_model.Lasso(alpha=0.01, random_state=13)\n",
    "lasso_poly.fit(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE \n",
    "print(\"RMSE d'une régression polynomiale régularisée :\")\n",
    "# Sur le jeu d'entrainement\n",
    "rmse_lasso_poly_train = metrics.root_mean_squared_error(y_train, lasso_poly.predict(X_train_poly))\n",
    "print(\"\\r train: {0:0.2f}\".format(rmse_lasso_poly_train))\n",
    "# Sur le jeu de test\n",
    "rmse_lasso_poly_test = metrics.root_mean_squared_error(y_test, lasso_poly.predict(X_test_poly))\n",
    "print(\"\\r test: {0:0.2f}\".format(rmse_lasso_poly_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144",
   "metadata": {},
   "source": [
    "Nous allons maintenant afficher le modèle appris sur le graphe précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dessiner le vrai modèle\n",
    "plt.plot(X_ground_truth, y_ground_truth, label=\"Vrai modèle\", linewidth=2)\n",
    "\n",
    "# Afficher le modèle appris\n",
    "plt.plot(X_ground_truth, lasso_poly.predict(X_ground_truth_poly), label=\"Modèle appris\", linewidth=2)\n",
    "\n",
    "# Afficher les données simulées\n",
    "plt.scatter(X_train, y_train, label=\"Données simulées (train)\", marker=\"o\")\n",
    "plt.scatter(X_test, y_test, label=\"Données simulées (test)\", marker=\"D\")\n",
    "\n",
    "# format plot\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Régression polynomiale régularisée l1\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Coefficients du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le nombre de variables\n",
    "num_features = X_train_poly.shape[1]\n",
    "\n",
    "# Afficher pour chaque variable son coefficient dans le modèle\n",
    "plt.scatter(range(num_features), # en abcisse : indices des variables\n",
    "            lasso_poly.coef_ # en ordonnées : leur poids dans le modèle\n",
    "           )\n",
    "\n",
    "# Étiqueter les axes\n",
    "tmp = plt.xlabel('Variable', fontsize=14)\n",
    "tmp = plt.ylabel('Coefficient', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
